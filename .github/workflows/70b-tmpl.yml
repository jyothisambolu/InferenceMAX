name: Template - LLaMA 70B

on:
  workflow_call:
    inputs:
      exp-name:
        required: true
        type: string
      isl:
        required: true
        type: string
      osl:
        required: true
        type: string
      max-model-len:
        required: true
        type: string
      random-range-ratio:
        required: true
        type: string

      use_h100:
        type: boolean
        required: true
      use_h200:
        type: boolean
        required: true
      use_b200:
        type: boolean
        required: true
      use_mi300x:
        type: boolean
        required: true
      use_mi325x:
        type: boolean
        required: true
      use_mi355x:
        type: boolean
        required: true

jobs:
  bmk-h100-fp8:
    if: ${{ github.event.inputs.use_h100 == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: h100
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[2, 4, 8]'

  bmk-h200-fp8:
    if: ${{ github.event.inputs.use_h200 == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: h200
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'

  bmk-h200-trt-fp8:
    if: ${{ github.event.inputs.use_h200 == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: h200-trt
      image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      framework: 'trt'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'  

  bmk-b200-fp8:
    if: ${{ github.event.inputs.use_b200 == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: b200
      image: 'kedarpotdar147/vllm:05'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2]'  

  bmk-b200-trt-fp8:
    if: ${{ github.event.inputs.use_b200 == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: b200-trt
      image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post1'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      framework: 'trt'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2]'  

  bmk-mi300x-fp8:
    if: ${{ github.event.inputs.use_mi300x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi300x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'

  bmk-mi300x-fp4:
    if: ${{ github.event.inputs.use_mi300x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi300x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-MXFP4-Preview'
      framework: 'vllm'
      precision: 'fp4'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'

  bmk-mi325x-fp8:
    if: ${{ github.event.inputs.use_mi325x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi325x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'

  bmk-mi325x-fp4:
    if: ${{ github.event.inputs.use_mi325x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi325x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-MXFP4-Preview'
      framework: 'vllm'
      precision: 'fp4'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2, 4, 8]'

  bmk-mi355x-fp8:
    if: ${{ github.event.inputs.use_mi355x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi355x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
      framework: 'vllm'
      precision: 'fp8'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2]'

  bmk-mi355x-fp4:
    if: ${{ github.event.inputs.use_mi355x == 'true' }}
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      runner: mi355x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-MXFP4-Preview'
      framework: 'vllm'
      precision: 'fp4'
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      tp-list: '[1, 2]'
