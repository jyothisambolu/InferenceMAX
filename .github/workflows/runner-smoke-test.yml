name: Test - Runner

run-name: '${{ github.event.inputs.runner }} - ${{ github.event.inputs.model }}'

on:
  workflow_dispatch:
    inputs:
      runner:
        description: 'Runner'
        required: true
        type: choice
        options:
          - 'h100-cr_0'
          - 'h100-cr_1'
          - 'h100-cw_0'
          - 'h100-cw_1'
          - 'h200-cw_0'
          - 'h200-cw_1'
          - 'h200-nb_0'
          - 'h200-nb_1'
          - 'h200-nb_2'
          - 'h200-nb_3'
          - 'h200-nv_0'
          - 'h200-nv_1'
          - 'h200-nv_2'
          - 'h200-nv_3'
          - 'b200-nv_0'
          - 'b200-nv_1'
          - 'b200-tg_0'
          - 'mi300x-amd_0'
          - 'mi300x-amd_1'
          - 'mi300x-amd_2'
          - 'mi300x-amd_3'
          - 'mi300x-amd_4'
          - 'mi300x-cr_0'
          - 'mi325x-amd_0'
          - 'mi325x-tw_0'
          - 'mi325x-tw_1'
          - 'mi325x-tw_2'
          - 'mi325x-tw_3'
          - 'mi355x-amd_0'
          - 'mi355x-amd_1'

      model:
        description: 'Model Type'
        required: true
        type: choice
        options:
          - 'nvidia/Llama-3.3-70B-Instruct-FP8'
          - 'amd/Llama-3.3-70B-Instruct-FP8-KV'
          - 'deepseek-ai/DeepSeek-R1-0528'
          - 'openai/gpt-oss-120b'

      image:
        description: 'Docker Image'
        required: true
        type: choice
        options:
          - 'kedarpotdar147/vllm0.1:latest'
          - 'kedarpotdar147/vllm:05'
          - 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
          - 'rocm/vllm-dev:open-mi300-08052025'
          - 'rocm/vllm-dev:open-mi355-08052025'
          - 'lmsysorg/sglang:v0.4.9.post1-cu126'
          - 'lmsysorg/sglang:v0.5.0rc1-cu128-b200'
          - 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_sgl-dev-v0.5.2rc2-mi30x_rc1'
          - 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2'

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  HF_HUB_CACHE: '/mnt/hf_hub_cache/'
  EXP_NAME: 'bmk-smoke-test'
  MODEL: ${{ inputs.model }}
  IMAGE: ${{ inputs.image }}
  ISL: 1024
  OSL: 1024
  MAX_MODEL_LEN: 2048
  RANDOM_RANGE_RATIO: 0.8
  TP: 8
  CONC: 4
  RESULT_FILENAME: 'bmk-smoke-test'

jobs:
  bmk-smoke-test:
    runs-on: ${{ inputs.runner }}
    steps:
      - uses: actions/checkout@v3
        with:
          token: ${{ secrets.REPO_PAT }}
          fetch-depth: 0

      - name: Resource cleanup
        run: |
          if command -v docker >/dev/null 2>&1 && docker info >/dev/null 2>&1; then
            echo "[Docker] Cleaning up resources ..."
            docker ps -aq | xargs -r docker rm -f
            docker network prune -f
            while [ -n "$(docker ps -aq)" ]; do
              docker ps -a
              sleep 5
            done
          fi
          if command -v squeue >/dev/null 2>&1; then
            echo "[Slurm] Cleaning up resources ..."
            scancel -u $USER
            while [ -n "$(squeue -u $USER --noheader --format='%i')" ]; do
              squeue -u $USER
              sleep 5
            done
          fi

      - name: Launch job script
        run: |
          RUNNER_NAME=${{ inputs.runner }}
          MODEL_HANDLE=$(
            if [[ "${{ env.MODEL }}" == *70B* ]]; then
              printf '70b'
            elif [[ "${{ env.MODEL }}" == *R1* ]]; then
              printf 'dsr1'
            else
              printf 'gptoss'
            fi
          )
          bash ./runners/launch_${RUNNER_NAME%%_*}*.sh $MODEL_HANDLE
          if [ ! -f "$RESULT_FILENAME.json" ]; then
            echo "Run failed: Benchmark result $RESULT_FILENAME.json not found." >&2
            exit 1
          fi

      - name: Process result
        run: |
          python3 utils/process_result.py ${{ inputs.runner }} $TP $RESULT_FILENAME $FRAMEWORK $PRECISION

      - name: Upload result
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.RESULT_FILENAME }}
          path: agg_${EXP_NAME}_tp${TP}_conc${CONC}_${RUNNER_NAME}.json
